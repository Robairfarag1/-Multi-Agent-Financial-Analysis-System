{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "901477c6",
   "metadata": {},
   "source": [
    "# Tech Monthly\n",
    "Adds **combined news sentiment** (Polygon + Finnhub), **earnings**, **sector & AI exposure indexes**, and **FRED macro lags**.\n",
    "\n",
    "Outputs CSVs and builds per‑ticker enriched features for modeling.\n",
    "\n",
    "## Purpose\n",
    "\n",
    "Build a monthly feature set for major tech stocks (AAPL, MSFT, GOOGL, NVDA, META, AMZN) by combining:\n",
    "\n",
    "* News sentiment (Polygon + Finnhub, merged & deduped)\n",
    "\n",
    "* Earnings surprises (Finnhub)\n",
    "\n",
    "* Sector & AI exposure indexes (yfinance)\n",
    "\n",
    "* Macro factors from FRED (with engineered features and lags)\n",
    "\n",
    "* TEST: run safe OLS regressions per ticker to see which features explain returns. All intermediate data are saved as CSVs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3490c64",
   "metadata": {},
   "source": [
    "## Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d981e97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "pandas 2.3.1\n"
     ]
    }
   ],
   "source": [
    "# If needed, install packages (uncomment):\n",
    "# !pip install requests pandas numpy scikit-learn statsmodels matplotlib yfinance pyarrow nltk\n",
    "\n",
    "import os, time, json, datetime as dt\n",
    "from typing import List, Dict, Any\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "\n",
    "print('pandas', pd.__version__)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f874f922",
   "metadata": {},
   "source": [
    "## Keys & controls\n",
    "\n",
    "* Defines tickers, date range (START = \"2015-01-01\" → END = today), and lag lengths [1,3,6].\n",
    "\n",
    "* Creates output folder data_enriched."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1256f09e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Keys present: {'FRED': True, 'POLYGON': True, 'FINNHUB': True}\n",
      "Universe: ['AAPL', 'MSFT', 'GOOGL', 'NVDA', 'META', 'AMZN']\n"
     ]
    }
   ],
   "source": [
    "FRED_KEY     = os.getenv(\"FRED_API_KEY\")\n",
    "POLYGON_KEY  = os.getenv(\"POLYGON_API_KEY\") \n",
    "FINNHUB_KEY  = os.getenv(\"FINNHUB_API_KEY\")\n",
    "\n",
    "FRED_BASE    = \"https://api.stlouisfed.org/fred/series/observations\"\n",
    "POLY_BASE    = \"https://api.polygon.io\"\n",
    "FINNHUB_BASE = \"https://finnhub.io/api/v1\"\n",
    "\n",
    "OUT_DIR = \"data_enriched\"\n",
    "os.makedirs(OUT_DIR, exist_ok=True)\n",
    "\n",
    "TECH_TICKERS = [\"AAPL\", \"MSFT\", \"GOOGL\", \"NVDA\", \"META\", \"AMZN\"]\n",
    "AI_BASKET    = [\"NVDA\", \"META\", \"MSFT\", \"GOOGL\", \"AMD\", \"AVGO\"]\n",
    "START  = \"2018-01-01\"\n",
    "END    = dt.date.today().isoformat()\n",
    "LAGS   = [1,3,6]\n",
    "\n",
    "print(\"Keys present:\", {\"FRED\": bool(FRED_KEY), \"POLYGON\": bool(POLYGON_KEY), \"FINNHUB\": bool(FINNHUB_KEY)})\n",
    "print(\"Universe:\", TECH_TICKERS)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec93cb2b",
   "metadata": {},
   "source": [
    "## Helpers — HTTP, CSV, lags, diagnostics\n",
    "\n",
    "* HTTP GET with retry, CSV saver, lag builder, simple diagnostics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "71a838f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_json(url: str, params: Dict[str, Any], max_retries=3, backoff=1.0):\n",
    "    for i in range(max_retries):\n",
    "        r = requests.get(url, params=params, timeout=30)\n",
    "        if r.status_code == 429:\n",
    "            time.sleep(backoff * (i+1) * 2)\n",
    "            continue\n",
    "        r.raise_for_status()\n",
    "        try:\n",
    "            return r.json()\n",
    "        except json.JSONDecodeError:\n",
    "            time.sleep(backoff)\n",
    "    raise RuntimeError(f\"GET failed after retries: {url}\")\n",
    "\n",
    "def _to_csv(df: pd.DataFrame, path: str):\n",
    "    df.to_csv(path, index=True)\n",
    "    print(f\"Saved → {path}\")\n",
    "\n",
    "def make_lags(df: pd.DataFrame, cols: List[str], lags=(1,3,6)) -> pd.DataFrame:\n",
    "    out = df.copy()\n",
    "    for c in cols:\n",
    "        if c not in out.columns: \n",
    "            continue\n",
    "        for L in lags:\n",
    "            out[f\"{c}_lag{L}\"] = out[c].shift(L)\n",
    "    return out\n",
    "\n",
    "def diagnostics(df: pd.DataFrame, name: str, top=10):\n",
    "    print(f\"\\n[Diag] {name}: shape={df.shape}, index=({df.index.min()}, {df.index.max()})\")\n",
    "    if df.index.duplicated().any():\n",
    "        dup = df.index[df.index.duplicated()]\n",
    "        print(f\"[Diag] WARNING: duplicate index rows={len(dup)}\")\n",
    "    na_pct = df.isna().mean().sort_values(ascending=False).head(top)\n",
    "    print(\"[Diag] Top columns by NaN%:\\n\", na_pct.to_string())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b118ffda",
   "metadata": {},
   "source": [
    "## FRED macro (monthly)\n",
    "\n",
    "* Pulls monthly Fed Funds, CPI, 10Y, Unemployment.\n",
    "\n",
    "* Engineers features: inflation_yoy, us10y_chg, fedfunds_chg, unrate_chg.\n",
    "\n",
    "* Saves macro_monthly.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f2de8b0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SyedM\\AppData\\Local\\Temp\\ipykernel_6708\\1053764871.py:15: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  return s.resample(\"M\").last() if how == \"last\" else s.resample(\"M\").mean()\n",
      "C:\\Users\\SyedM\\AppData\\Local\\Temp\\ipykernel_6708\\1053764871.py:15: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  return s.resample(\"M\").last() if how == \"last\" else s.resample(\"M\").mean()\n",
      "C:\\Users\\SyedM\\AppData\\Local\\Temp\\ipykernel_6708\\1053764871.py:15: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  return s.resample(\"M\").last() if how == \"last\" else s.resample(\"M\").mean()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Diag] macro monthly: shape=(94, 8), index=(2018-01-31 00:00:00, 2025-10-31 00:00:00)\n",
      "[Diag] Top columns by NaN%:\n",
      " inflation_yoy        0.127660\n",
      "unrate_chg           0.031915\n",
      "cpi_index            0.021277\n",
      "unemployment_rate    0.021277\n",
      "fedfunds_chg         0.021277\n",
      "fed_funds_rate       0.010638\n",
      "us10y_chg            0.010638\n",
      "us10y                0.000000\n",
      "Saved → data_enriched/macro_monthly.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SyedM\\AppData\\Local\\Temp\\ipykernel_6708\\1053764871.py:15: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  return s.resample(\"M\").last() if how == \"last\" else s.resample(\"M\").mean()\n",
      "C:\\Users\\SyedM\\AppData\\Local\\Temp\\ipykernel_6708\\1053764871.py:25: FutureWarning: The default fill_method='pad' in Series.pct_change is deprecated and will be removed in a future version. Either fill in any non-leading NA values prior to calling pct_change or specify 'fill_method=None' to not fill NA values.\n",
      "  macro[\"inflation_yoy\"] = macro[\"cpi_index\"].pct_change(12) * 100\n"
     ]
    }
   ],
   "source": [
    "def fred_series_monthly(series_id: str, start: str, end: str, how=\"mean\") -> pd.Series:\n",
    "    if not FRED_KEY:\n",
    "        raise RuntimeError(\"Missing FRED_API_KEY\")\n",
    "    url = FRED_BASE\n",
    "    params = {\"series_id\":series_id, \"api_key\":FRED_KEY, \"file_type\":\"json\",\n",
    "              \"observation_start\":start, \"observation_end\":end}\n",
    "    js = _get_json(url, params)\n",
    "    obs = js.get(\"observations\", [])\n",
    "    if not obs:\n",
    "        return pd.Series(dtype=float)\n",
    "    df = pd.DataFrame(obs)\n",
    "    df[\"date\"] = pd.to_datetime(df[\"date\"])\n",
    "    df[\"value\"] = pd.to_numeric(df[\"value\"], errors=\"coerce\")\n",
    "    s = df.set_index(\"date\")[\"value\"].astype(float)\n",
    "    return s.resample(\"M\").last() if how == \"last\" else s.resample(\"M\").mean()\n",
    "\n",
    "def get_macro_block(start: str, end: str) -> pd.DataFrame:\n",
    "    series = {\"FEDFUNDS\":\"fed_funds_rate\", \"CPIAUCSL\":\"cpi_index\", \"DGS10\":\"us10y\", \"UNRATE\":\"unemployment_rate\"}\n",
    "    cols = {}\n",
    "    for sid, name in series.items():\n",
    "        cols[name] = fred_series_monthly(sid, start, end, how=\"mean\")\n",
    "    macro = pd.DataFrame(cols).sort_index()\n",
    "    # Engineered features\n",
    "    if \"cpi_index\" in macro:\n",
    "        macro[\"inflation_yoy\"] = macro[\"cpi_index\"].pct_change(12) * 100\n",
    "    if \"us10y\" in macro:\n",
    "        macro[\"us10y_chg\"] = macro[\"us10y\"].diff(1)\n",
    "    if \"fed_funds_rate\" in macro:\n",
    "        macro[\"fedfunds_chg\"] = macro[\"fed_funds_rate\"].diff(1)\n",
    "    if \"unemployment_rate\" in macro:\n",
    "        macro[\"unrate_chg\"] = macro[\"unemployment_rate\"].diff(1)\n",
    "    diagnostics(macro, \"macro monthly\")\n",
    "    _to_csv(macro, f\"{OUT_DIR}/macro_monthly.csv\")\n",
    "    return macro\n",
    "\n",
    "macro = get_macro_block(START, END)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "852eed4e",
   "metadata": {},
   "source": [
    "## Prices & sector / AI indexes (yfinance)\n",
    "\n",
    "* Computes monthly returns for NASDAQ Composite (^IXIC) and XLK.\n",
    "\n",
    "* Builds AI basket (equal-weight ret of NVDA, META, MSFT, GOOGL, AMD, AVGO).\n",
    "\n",
    "* Saves ixic_rets.csv, xlk_rets.csv, ai_basket_rets.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7b4a8977",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SyedM\\AppData\\Local\\Temp\\ipykernel_6708\\934960800.py:9: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  m = close.resample(\"M\").last()\n",
      "C:\\Users\\SyedM\\AppData\\Local\\Temp\\ipykernel_6708\\934960800.py:9: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  m = close.resample(\"M\").last()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved → data_enriched/ixic_rets.csv\n",
      "Saved → data_enriched/xlk_rets.csv\n",
      "Saved → data_enriched/ai_basket_rets.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SyedM\\AppData\\Local\\Temp\\ipykernel_6708\\934960800.py:9: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  m = close.resample(\"M\").last()\n"
     ]
    }
   ],
   "source": [
    "def monthly_from_yf(tickers, start, end):\n",
    "    data = yf.download(tickers, start=start, end=end, progress=False, auto_adjust=True)\n",
    "    if isinstance(tickers, str) or (isinstance(tickers, list) and len(tickers) == 1):\n",
    "        close = data[\"Close\"]\n",
    "        if isinstance(close, pd.Series):\n",
    "            close = close.to_frame(name=tickers if isinstance(tickers, str) else tickers[0])\n",
    "    else:\n",
    "        close = data[\"Close\"]\n",
    "    m = close.resample(\"M\").last()\n",
    "    rets = m.pct_change()\n",
    "    return m, rets\n",
    "\n",
    "ixic_close, ixic_rets = monthly_from_yf(\"^IXIC\", START, END); ixic_rets.columns = [\"ixic_ret\"]\n",
    "xlk_close,  xlk_rets  = monthly_from_yf(\"XLK\",  START, END);  xlk_rets.columns  = [\"xlk_ret\"]\n",
    "\n",
    "ai_close, ai_rets = monthly_from_yf([\"NVDA\",\"META\",\"MSFT\",\"GOOGL\",\"AMD\",\"AVGO\"], START, END)\n",
    "ai_ret_eqw = ai_rets.mean(axis=1).to_frame(name=\"ai_basket_ret\")\n",
    "\n",
    "_to_csv(ixic_rets, f\"{OUT_DIR}/ixic_rets.csv\")\n",
    "_to_csv(xlk_rets,  f\"{OUT_DIR}/xlk_rets.csv\")\n",
    "_to_csv(ai_ret_eqw, f\"{OUT_DIR}/ai_basket_rets.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ed580f",
   "metadata": {},
   "source": [
    "## Combined news sentiment (Polygon + Finnhub)\n",
    "\n",
    "* Fetches news from both APIs, fault-tolerant (soft failure if one is down).\n",
    "\n",
    "* Coerces timestamps to datetimes, dedupes near-duplicate headlines within a few days.\n",
    "\n",
    "* Scores sentiment per article with VADER (fallback keyword heuristic).\n",
    "\n",
    "* Aggregates monthly:\n",
    "\n",
    "    * sent_mean, sent_count (all articles both sources)\n",
    "\n",
    "    * sent_mean_weighted (count-weighted blend of source means)\n",
    "\n",
    "    * Per-source diagnostics: sent_mean_poly, sent_count_poly, sent_mean_fin, sent_count_fin\n",
    "\n",
    "* *aves per-ticker *_news_sentiment_combined.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4c68b0cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined sentiment for AAPL ...\n",
      "[warn] _get_json_safe failed: https://api.polygon.io/v2/reference/news | HTTPError: 400 Client Error: Bad Request for url: https://api.polygon.io/v2/reference/news?ticker=AAPL&limit=1000&order=desc&apiKey=TNRyzBuL5CNEIxE3aGKd66ssjVJkVq8B&cursor=https%3A%2F%2Fapi.polygon.io%2Fv2%2Freference%2Fnews%3Fcursor%3DYXA9MjAyNS0wMy0xOVQwOCUzQTIxJTNBMDBaJmFzPTA2MDY2ZTFhM2VkZTY1NzNhMjNiYzEzMGRjMTczMmJlNDBkYzFlYTczYWI4MjA4YzI0OGU2MDZhZWMyNWFiMjImbGltaXQ9MTAwMCZvcmRlcj1kZXNjZW5kaW5nJnRpY2tlcj1BQVBM\n",
      "[warn] Finnhub news empty for AAPL in 2018-01-01→2019-01-01\n",
      "[warn] Finnhub news empty for AAPL in 2019-01-02→2020-01-02\n",
      "[warn] Finnhub news empty for AAPL in 2020-01-03→2021-01-02\n",
      "[warn] Finnhub news empty for AAPL in 2021-01-03→2022-01-03\n",
      "[warn] Finnhub news empty for AAPL in 2022-01-04→2023-01-04\n",
      "[warn] Finnhub news empty for AAPL in 2023-01-05→2024-01-05\n",
      "Saved → data_enriched/AAPL_news_sentiment_combined.csv\n",
      "Combined sentiment for MSFT ...\n",
      "[warn] _get_json_safe failed: https://api.polygon.io/v2/reference/news | NoneType: None\n",
      "[warn] Finnhub news empty for MSFT in 2018-01-01→2019-01-01\n",
      "[warn] Finnhub news empty for MSFT in 2019-01-02→2020-01-02\n",
      "[warn] Finnhub news empty for MSFT in 2020-01-03→2021-01-02\n",
      "[warn] Finnhub news empty for MSFT in 2021-01-03→2022-01-03\n",
      "[warn] Finnhub news empty for MSFT in 2022-01-04→2023-01-04\n",
      "[warn] Finnhub news empty for MSFT in 2023-01-05→2024-01-05\n",
      "Saved → data_enriched/MSFT_news_sentiment_combined.csv\n",
      "Combined sentiment for GOOGL ...\n",
      "[warn] _get_json_safe failed: https://api.polygon.io/v2/reference/news | HTTPError: 400 Client Error: Bad Request for url: https://api.polygon.io/v2/reference/news?ticker=GOOGL&limit=1000&order=desc&apiKey=TNRyzBuL5CNEIxE3aGKd66ssjVJkVq8B&cursor=https%3A%2F%2Fapi.polygon.io%2Fv2%2Freference%2Fnews%3Fcursor%3DYXA9MjAyNS0wNC0wM1QxMSUzQTMwJTNBMDBaJmFzPTJjN2FmM2E5NTgzNWRiYjMwOTliNzhlNzBlMmI2NzQxYTM3MzgxZTk1ZGVhOWY2MzlmYTdjYjg3M2Y2NmM1MjcmbGltaXQ9MTAwMCZvcmRlcj1kZXNjZW5kaW5nJnRpY2tlcj1HT09HTA\n",
      "[warn] Finnhub news empty for GOOGL in 2018-01-01→2019-01-01\n",
      "[warn] Finnhub news empty for GOOGL in 2019-01-02→2020-01-02\n",
      "[warn] Finnhub news empty for GOOGL in 2020-01-03→2021-01-02\n",
      "[warn] Finnhub news empty for GOOGL in 2021-01-03→2022-01-03\n",
      "[warn] Finnhub news empty for GOOGL in 2022-01-04→2023-01-04\n",
      "[warn] Finnhub news empty for GOOGL in 2023-01-05→2024-01-05\n",
      "Saved → data_enriched/GOOGL_news_sentiment_combined.csv\n",
      "Combined sentiment for NVDA ...\n",
      "[warn] _get_json_safe failed: https://api.polygon.io/v2/reference/news | NoneType: None\n",
      "[warn] Finnhub news empty for NVDA in 2018-01-01→2019-01-01\n",
      "[warn] Finnhub news empty for NVDA in 2019-01-02→2020-01-02\n",
      "[warn] Finnhub news empty for NVDA in 2020-01-03→2021-01-02\n",
      "[warn] Finnhub news empty for NVDA in 2021-01-03→2022-01-03\n",
      "[warn] Finnhub news empty for NVDA in 2022-01-04→2023-01-04\n",
      "[warn] Finnhub news empty for NVDA in 2023-01-05→2024-01-05\n",
      "Saved → data_enriched/NVDA_news_sentiment_combined.csv\n",
      "Combined sentiment for META ...\n",
      "[warn] _get_json_safe failed: https://api.polygon.io/v2/reference/news | NoneType: None\n",
      "[warn] Polygon news empty for META (pages=0).\n",
      "[warn] Finnhub news empty for META in 2018-01-01→2019-01-01\n",
      "[warn] Finnhub news empty for META in 2019-01-02→2020-01-02\n",
      "[warn] Finnhub news empty for META in 2020-01-03→2021-01-02\n",
      "[warn] Finnhub news empty for META in 2021-01-03→2022-01-03\n",
      "[warn] Finnhub news empty for META in 2022-01-04→2023-01-04\n",
      "[warn] Finnhub news empty for META in 2023-01-05→2024-01-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SyedM\\AppData\\Local\\Temp\\ipykernel_6708\\2344229441.py:154: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined = pd.concat([poly_df, fin_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved → data_enriched/META_news_sentiment_combined.csv\n",
      "Combined sentiment for AMZN ...\n",
      "[warn] _get_json_safe failed: https://api.polygon.io/v2/reference/news | NoneType: None\n",
      "[warn] Polygon news empty for AMZN (pages=0).\n",
      "[warn] Finnhub news empty for AMZN in 2018-01-01→2019-01-01\n",
      "[warn] Finnhub news empty for AMZN in 2019-01-02→2020-01-02\n",
      "[warn] Finnhub news empty for AMZN in 2020-01-03→2021-01-02\n",
      "[warn] Finnhub news empty for AMZN in 2021-01-03→2022-01-03\n",
      "[warn] Finnhub news empty for AMZN in 2022-01-04→2023-01-04\n",
      "[warn] Finnhub news empty for AMZN in 2023-01-05→2024-01-05\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SyedM\\AppData\\Local\\Temp\\ipykernel_6708\\2344229441.py:154: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
      "  combined = pd.concat([poly_df, fin_df], ignore_index=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved → data_enriched/AMZN_news_sentiment_combined.csv\n"
     ]
    }
   ],
   "source": [
    "def _get_json_safe(url: str, params: dict, max_retries=3, backoff=1.5):\n",
    "    last_err = None\n",
    "    for i in range(max_retries):\n",
    "        try:\n",
    "            r = requests.get(url, params=params, timeout=30)\n",
    "            if r.status_code == 429:  # rate limited\n",
    "                time.sleep(backoff * (i + 1))\n",
    "                continue\n",
    "            r.raise_for_status()\n",
    "            try:\n",
    "                return r.json()\n",
    "            except json.JSONDecodeError as e:\n",
    "                last_err = e\n",
    "                time.sleep(backoff)\n",
    "                continue\n",
    "        except Exception as e:\n",
    "            last_err = e\n",
    "            time.sleep(backoff)\n",
    "    print(f\"[warn] _get_json_safe failed: {url} | {type(last_err).__name__}: {last_err}\")\n",
    "    return None  # <-- crucial: fail soft\n",
    "\n",
    "def polygon_news_raw(ticker: str, api_key: str, start=None, end=None, max_pages=20, page_limit=1000, sleep=0.4):\n",
    "    \"\"\"\n",
    "    Paginate Polygon /v2/reference/news using the 'cursor' token.\n",
    "    Stops when:\n",
    "      - no more pages\n",
    "      - hit max_pages\n",
    "      - (optional) item date < start (fast-exit filter)\n",
    "    Returns standardized columns: [date, headline, summary, source]\n",
    "    \"\"\"\n",
    "    cols = [\"date\",\"headline\",\"summary\",\"source\"]\n",
    "    if not api_key:\n",
    "        return pd.DataFrame(columns=cols)\n",
    "\n",
    "    url = f\"{POLY_BASE}/v2/reference/news\"\n",
    "    params = {\n",
    "        \"ticker\": ticker,\n",
    "        \"limit\": min(page_limit, 1000),\n",
    "        \"order\": \"desc\",\n",
    "        \"apiKey\": api_key,\n",
    "    }\n",
    "    if start: params[\"published_utc.gte\"] = pd.Timestamp(start).strftime(\"%Y-%m-%d\")\n",
    "    if end:   params[\"published_utc.lte\"] = pd.Timestamp(end).strftime(\"%Y-%m-%d\")\n",
    "\n",
    "    all_rows = []\n",
    "    cursor = None\n",
    "    pages = 0\n",
    "\n",
    "    while True:\n",
    "        if cursor:\n",
    "            params[\"cursor\"] = cursor\n",
    "        js = _get_json_safe(url, params)\n",
    "        if not js or \"results\" not in js or not js[\"results\"]:\n",
    "            break\n",
    "\n",
    "        rows = js[\"results\"]\n",
    "        for r in rows:\n",
    "            d  = pd.to_datetime(r.get(\"published_utc\"), errors=\"coerce\")\n",
    "            tl = r.get(\"title\", \"\")\n",
    "            ds = r.get(\"description\", \"\")\n",
    "            if pd.isna(d): \n",
    "                continue\n",
    "            # optional fast-exit if we already scrolled past 'start'\n",
    "            if start and d < pd.Timestamp(start):\n",
    "                break\n",
    "            all_rows.append({\"date\": d, \"headline\": tl, \"summary\": ds, \"source\": \"polygon\"})\n",
    "\n",
    "        pages += 1\n",
    "        cursor = js.get(\"next_url\") or js.get(\"next\") or js.get(\"cursor\")\n",
    "        if not cursor or pages >= max_pages:\n",
    "            break\n",
    "        time.sleep(sleep)\n",
    "\n",
    "    if not all_rows:\n",
    "        print(f\"[warn] Polygon news empty for {ticker} (pages={pages}).\")\n",
    "        return pd.DataFrame(columns=cols)\n",
    "\n",
    "    df = pd.DataFrame(all_rows).sort_values(\"date\")\n",
    "    return df[cols]\n",
    "\n",
    "def finnhub_news_raw(ticker: str, api_key: str, start: str, end: str, chunk=\"365D\", sleep=0.3):\n",
    "    \"\"\"\n",
    "    Fetch Finnhub company-news in date chunks (e.g., per ~year) to avoid silent truncation.\n",
    "    Returns standardized columns: [date, headline, summary, source]\n",
    "    \"\"\"\n",
    "    cols = [\"date\",\"headline\",\"summary\",\"source\"]\n",
    "    if not api_key:\n",
    "        return pd.DataFrame(columns=cols)\n",
    "\n",
    "    start_ts = pd.Timestamp(start)\n",
    "    end_ts   = pd.Timestamp(end)\n",
    "    step     = pd.Timedelta(chunk)\n",
    "\n",
    "    frames = []\n",
    "    lo = start_ts\n",
    "    while lo <= end_ts:\n",
    "        hi = min(lo + step, end_ts)\n",
    "        url = f\"{FINNHUB_BASE}/company-news\"\n",
    "        params = {\"symbol\": ticker, \"from\": lo.date().isoformat(), \"to\": hi.date().isoformat(), \"token\": api_key}\n",
    "        js = _get_json_safe(url, params)\n",
    "        if isinstance(js, list) and js:\n",
    "            df = pd.DataFrame(js)\n",
    "            d  = pd.to_datetime(df.get(\"datetime\"), unit=\"s\", errors=\"coerce\")\n",
    "            if d.isna().all():\n",
    "                d = pd.to_datetime(df.get(\"time\"), unit=\"ms\", errors=\"coerce\")\n",
    "            df_out = pd.DataFrame({\n",
    "                \"date\": d,\n",
    "                \"headline\": df.get(\"headline\", \"\"),\n",
    "                \"summary\":  df.get(\"summary\", \"\"),\n",
    "                \"source\":   \"finnhub\"\n",
    "            }).dropna(subset=[\"date\"])\n",
    "            if not df_out.empty:\n",
    "                frames.append(df_out)\n",
    "        else:\n",
    "            print(f\"[warn] Finnhub news empty for {ticker} in {lo.date()}→{hi.date()}\")\n",
    "        lo = hi + pd.Timedelta(\"1D\")\n",
    "        time.sleep(sleep)\n",
    "\n",
    "    if not frames:\n",
    "        return pd.DataFrame(columns=cols)\n",
    "    return pd.concat(frames, ignore_index=True).sort_values(\"date\")[cols]\n",
    "\n",
    "\n",
    "# Ensure VADER or fallback exists (reuse from earlier cell if present)\n",
    "try:\n",
    "    from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "    _ = SentimentIntensityAnalyzer()\n",
    "    _VADER_OK = True\n",
    "except Exception:\n",
    "    _VADER_OK = False\n",
    "\n",
    "def simple_sentiment(text: str) -> float:\n",
    "    if not isinstance(text, str) or not text.strip():\n",
    "        return 0.0\n",
    "    if _VADER_OK:\n",
    "        sia = SentimentIntensityAnalyzer()\n",
    "        return float(sia.polarity_scores(text)[\"compound\"])\n",
    "    t = text.lower()\n",
    "    pos = sum(w in t for w in [\"beat\",\"record\",\"growth\",\"surge\",\"profit\",\"upgrade\",\"outperform\",\"strong\",\"rally\"])\n",
    "    neg = sum(w in t for w in [\"miss\",\"cut\",\"probe\",\"lawsuit\",\"downgrade\",\"decline\",\"headwind\",\"weak\",\"plunge\"])\n",
    "    return (pos - neg) / 6.0\n",
    "\n",
    "def build_monthly_news_sentiment_combined(\n",
    "    ticker: str,\n",
    "    start: str,\n",
    "    end: str,\n",
    "    polygon_key: str,\n",
    "    finnhub_key: str,\n",
    "    dedup_within_days: int = 3\n",
    ") -> pd.DataFrame:\n",
    "    # Pull both; either may be empty if API failed\n",
    "    poly_df = polygon_news_raw(ticker, polygon_key)\n",
    "    fin_df  = finnhub_news_raw(ticker, finnhub_key, start, end)\n",
    "    combined = pd.concat([poly_df, fin_df], ignore_index=True)\n",
    "\n",
    "    # Sanitize\n",
    "    combined[\"date\"] = pd.to_datetime(combined.get(\"date\"), errors=\"coerce\", utc=True)\n",
    "    combined = combined.dropna(subset=[\"date\"]).copy()\n",
    "    try:\n",
    "        combined[\"date\"] = combined[\"date\"].dt.tz_convert(None)\n",
    "    except Exception:\n",
    "        pass\n",
    "    for col in [\"headline\",\"summary\"]:\n",
    "        if col not in combined.columns:\n",
    "            combined[col] = \"\"\n",
    "        combined[col] = combined[col].fillna(\"\").astype(str)\n",
    "\n",
    "    if combined.empty:\n",
    "        cols = [\"sent_mean\",\"sent_count\",\"sent_mean_weighted\",\"sent_mean_poly\",\"sent_count_poly\",\"sent_mean_fin\",\"sent_count_fin\"]\n",
    "        return pd.DataFrame(columns=cols, dtype=float)\n",
    "\n",
    "    # Deduplicate within window by (floor(date), headline)\n",
    "    if dedup_within_days and dedup_within_days > 0:\n",
    "        rd = f\"{dedup_within_days}D\"\n",
    "        combined[\"date_round\"] = combined[\"date\"].dt.floor(rd)\n",
    "        combined = combined.drop_duplicates(subset=[\"date_round\",\"headline\"])\n",
    "\n",
    "    # Sentiment & monthly bins\n",
    "    texts = combined[\"headline\"] + \". \" + combined[\"summary\"]\n",
    "    combined[\"sent\"] = texts.apply(simple_sentiment)\n",
    "    combined[\"month\"] = combined[\"date\"].dt.to_period(\"M\").dt.to_timestamp(\"M\")\n",
    "\n",
    "    # Per-source monthly stats\n",
    "    src = combined.groupby([\"month\",\"source\"]).agg(\n",
    "        sent_mean=(\"sent\",\"mean\"),\n",
    "        sent_count=(\"sent\",\"size\")\n",
    "    ).reset_index()\n",
    "    src_piv = src.pivot(index=\"month\", columns=\"source\", values=[\"sent_mean\",\"sent_count\"])\n",
    "\n",
    "    # Ensure expected columns exist\n",
    "    for c in [(\"sent_mean\",\"polygon\"), (\"sent_mean\",\"finnhub\"), (\"sent_count\",\"polygon\"), (\"sent_count\",\"finnhub\")]:\n",
    "        if c not in src_piv.columns:\n",
    "            src_piv[c] = np.nan if \"mean\" in c[0] else 0\n",
    "    src_piv = src_piv.sort_index()\n",
    "\n",
    "    out = pd.DataFrame(index=src_piv.index)\n",
    "    out[\"sent_mean_poly\"]  = src_piv[(\"sent_mean\",\"polygon\")]\n",
    "    out[\"sent_count_poly\"] = src_piv[(\"sent_count\",\"polygon\")].fillna(0).astype(int)\n",
    "    out[\"sent_mean_fin\"]   = src_piv[(\"sent_mean\",\"finnhub\")]\n",
    "    out[\"sent_count_fin\"]  = src_piv[(\"sent_count\",\"finnhub\")].fillna(0).astype(int)\n",
    "\n",
    "    # Combined article-level mean & count\n",
    "    all_month = combined.groupby(\"month\").agg(sent_mean=(\"sent\",\"mean\"), sent_count=(\"sent\",\"size\"))\n",
    "    out = out.join(all_month, how=\"outer\")\n",
    "\n",
    "    # Count-weighted per-source mean\n",
    "    num = (out[\"sent_mean_poly\"].fillna(0) * out[\"sent_count_poly\"].astype(float) +\n",
    "           out[\"sent_mean_fin\"].fillna(0)  * out[\"sent_count_fin\"].astype(float))\n",
    "    den = (out[\"sent_count_poly\"].astype(float) + out[\"sent_count_fin\"].astype(float))\n",
    "    out[\"sent_mean_weighted\"] = np.where(den > 0, num / den, np.nan)\n",
    "\n",
    "    return out[[\n",
    "        \"sent_mean\",\"sent_count\",\"sent_mean_weighted\",\n",
    "        \"sent_mean_poly\",\"sent_count_poly\",\"sent_mean_fin\",\"sent_count_fin\"\n",
    "    ]].sort_index()\n",
    "\n",
    "news_sent_maps = {}\n",
    "for t in TECH_TICKERS:\n",
    "    print(f\"Combined sentiment for {t} ...\")\n",
    "    s = build_monthly_news_sentiment_combined(t, START, END, POLYGON_KEY, FINNHUB_KEY)\n",
    "    news_sent_maps[t] = s\n",
    "    _to_csv(s, f\"{OUT_DIR}/{t}_news_sentiment_combined.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "186e9fcd",
   "metadata": {},
   "source": [
    "## Earnings features (Finnhub)\n",
    "\n",
    "* Pulls quarterly EPS actual/estimate; computes surprise %.\n",
    "\n",
    "* Aggregates to monthly: eps_surprise_mean, eps_surprise_last.\n",
    "\n",
    "* Saves per-ticker *_earnings_features.csv."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6cf215ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Earnings features for AAPL ...\n",
      "Saved → data_enriched/AAPL_earnings_features.csv\n",
      "Earnings features for MSFT ...\n",
      "Saved → data_enriched/MSFT_earnings_features.csv\n",
      "Earnings features for GOOGL ...\n",
      "Saved → data_enriched/GOOGL_earnings_features.csv\n",
      "Earnings features for NVDA ...\n",
      "Saved → data_enriched/NVDA_earnings_features.csv\n",
      "Earnings features for META ...\n",
      "Saved → data_enriched/META_earnings_features.csv\n",
      "Earnings features for AMZN ...\n",
      "Saved → data_enriched/AMZN_earnings_features.csv\n"
     ]
    }
   ],
   "source": [
    "def finnhub_earnings(ticker: str, start: str, end: str) -> pd.DataFrame:\n",
    "    if not FINNHUB_KEY:\n",
    "        return pd.DataFrame(columns=[\"date\",\"epsActual\",\"epsEstimate\",\"surprisePercent\"])\n",
    "    url = f\"{FINNHUB_BASE}/stock/earnings\"\n",
    "    params = {\"symbol\": ticker, \"token\": FINNHUB_KEY}\n",
    "    js = _get_json(url, params)\n",
    "    if not isinstance(js, list) or len(js) == 0:\n",
    "        url2 = f\"{FINNHUB_BASE}/calendar/earnings\"\n",
    "        params2 = {\"from\": start, \"to\": end, \"token\": FINNHUB_KEY}\n",
    "        js2 = _get_json(url2, params2)\n",
    "        df2 = pd.DataFrame(js2.get(\"earningsCalendar\", []))\n",
    "        if df2.empty:\n",
    "            return pd.DataFrame(columns=[\"date\",\"epsActual\",\"epsEstimate\",\"surprisePercent\"])\n",
    "        df2[\"date\"] = pd.to_datetime(df2[\"date\"], errors=\"coerce\")\n",
    "        df2 = df2[df2.get(\"symbol\",\"\") == ticker]\n",
    "        keep = [c for c in [\"date\",\"epsActual\",\"epsEstimate\",\"surprisePercent\"] if c in df2.columns]\n",
    "        return df2[keep].dropna(subset=[\"date\"]).sort_values(\"date\")\n",
    "    df = pd.DataFrame(js)\n",
    "    if \"date\" in df.columns:\n",
    "        df[\"date\"] = pd.to_datetime(df[\"date\"], errors=\"coerce\")\n",
    "    elif \"period\" in df.columns:\n",
    "        df[\"date\"] = pd.to_datetime(df[\"period\"], errors=\"coerce\")\n",
    "    if \"surprisePercent\" not in df.columns and {\"epsActual\",\"epsEstimate\"} <= set(df.columns):\n",
    "        with np.errstate(divide='ignore', invalid='ignore'):\n",
    "            df[\"surprisePercent\"] = (df[\"epsActual\"] - df[\"epsEstimate\"]) / df[\"epsEstimate\"] * 100.0\n",
    "    keep = [c for c in [\"date\",\"epsActual\",\"epsEstimate\",\"surprisePercent\"] if c in df.columns]\n",
    "    return df[keep].dropna(subset=[\"date\"]).sort_values(\"date\")\n",
    "\n",
    "def monthly_earnings_features(ticker: str) -> pd.DataFrame:\n",
    "    df = finnhub_earnings(ticker, START, END)\n",
    "    if df.empty:\n",
    "        return pd.DataFrame(columns=[\"month\",\"eps_surprise_mean\",\"eps_surprise_last\"]).set_index(\"month\")\n",
    "    df[\"month\"] = df[\"date\"].dt.to_period(\"M\").dt.to_timestamp(\"M\")\n",
    "    agg = df.groupby(\"month\").agg(eps_surprise_mean=(\"surprisePercent\",\"mean\"),\n",
    "                                  eps_surprise_last=(\"surprisePercent\",\"last\")).sort_index()\n",
    "    return agg\n",
    "\n",
    "earnings_maps = {}\n",
    "for t in TECH_TICKERS:\n",
    "    print(f\"Earnings features for {t} ...\")\n",
    "    e = monthly_earnings_features(t)\n",
    "    earnings_maps[t] = e\n",
    "    _to_csv(e, f\"{OUT_DIR}/{t}_earnings_features.csv\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9982f93",
   "metadata": {},
   "source": [
    "## Build per‑ticker enriched features\n",
    "\n",
    "* For each ticker: joins monthly returns with IXIC, XLK, AI basket, news sentiment, earnings, and macro lags (to avoid leakage).\n",
    "\n",
    "* Trims early rows to respect lag availability.\n",
    "\n",
    "* Saves per-ticker *_features_enriched.csv and a tech_features_combined.csv (wide panel)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "31427adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Features for AAPL ...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SyedM\\AppData\\Local\\Temp\\ipykernel_6708\\934960800.py:9: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  m = close.resample(\"M\").last()\n",
      "C:\\Users\\SyedM\\AppData\\Local\\Temp\\ipykernel_6708\\934960800.py:9: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  m = close.resample(\"M\").last()\n",
      "C:\\Users\\SyedM\\AppData\\Local\\Temp\\ipykernel_6708\\934960800.py:9: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  m = close.resample(\"M\").last()\n",
      "C:\\Users\\SyedM\\AppData\\Local\\Temp\\ipykernel_6708\\934960800.py:9: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  m = close.resample(\"M\").last()\n",
      "C:\\Users\\SyedM\\AppData\\Local\\Temp\\ipykernel_6708\\934960800.py:9: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  m = close.resample(\"M\").last()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[Diag] AAPL features: shape=(88, 42), index=(2018-07-31 00:00:00, 2025-10-31 00:00:00)\n",
      "[Diag] Top columns by NaN%:\n",
      " sent_mean_fin         0.954545\n",
      "eps_surprise_mean     0.954545\n",
      "eps_surprise_last     0.954545\n",
      "sent_mean_poly        0.909091\n",
      "sent_mean_weighted    0.886364\n",
      "sent_count_poly       0.886364\n",
      "sent_count            0.886364\n",
      "sent_count_fin        0.886364\n",
      "sent_mean             0.886364\n",
      "inflation_yoy_lag6    0.136364\n",
      "Saved → data_enriched/AAPL_features_enriched.csv\n",
      "Features for MSFT ...\n",
      "\n",
      "[Diag] MSFT features: shape=(88, 42), index=(2018-07-31 00:00:00, 2025-10-31 00:00:00)\n",
      "[Diag] Top columns by NaN%:\n",
      " sent_mean_fin         0.954545\n",
      "eps_surprise_mean     0.954545\n",
      "eps_surprise_last     0.954545\n",
      "sent_mean_poly        0.909091\n",
      "sent_mean_weighted    0.886364\n",
      "sent_count_poly       0.886364\n",
      "sent_count            0.886364\n",
      "sent_count_fin        0.886364\n",
      "sent_mean             0.886364\n",
      "inflation_yoy_lag6    0.136364\n",
      "Saved → data_enriched/MSFT_features_enriched.csv\n",
      "Features for GOOGL ...\n",
      "\n",
      "[Diag] GOOGL features: shape=(88, 42), index=(2018-07-31 00:00:00, 2025-10-31 00:00:00)\n",
      "[Diag] Top columns by NaN%:\n",
      " sent_mean_fin         0.954545\n",
      "eps_surprise_mean     0.954545\n",
      "eps_surprise_last     0.954545\n",
      "sent_mean_poly        0.920455\n",
      "sent_mean_weighted    0.897727\n",
      "sent_count_poly       0.897727\n",
      "sent_count            0.897727\n",
      "sent_count_fin        0.897727\n",
      "sent_mean             0.897727\n",
      "inflation_yoy_lag6    0.136364\n",
      "Saved → data_enriched/GOOGL_features_enriched.csv\n",
      "Features for NVDA ...\n",
      "\n",
      "[Diag] NVDA features: shape=(88, 42), index=(2018-07-31 00:00:00, 2025-10-31 00:00:00)\n",
      "[Diag] Top columns by NaN%:\n",
      " sent_mean_poly        0.954545\n",
      "sent_mean_fin         0.954545\n",
      "eps_surprise_last     0.954545\n",
      "eps_surprise_mean     0.954545\n",
      "sent_mean_weighted    0.931818\n",
      "sent_count_poly       0.931818\n",
      "sent_count            0.931818\n",
      "sent_count_fin        0.931818\n",
      "sent_mean             0.931818\n",
      "inflation_yoy_lag6    0.136364\n",
      "Saved → data_enriched/NVDA_features_enriched.csv\n",
      "Features for META ...\n",
      "\n",
      "[Diag] META features: shape=(88, 42), index=(2018-07-31 00:00:00, 2025-10-31 00:00:00)\n",
      "[Diag] Top columns by NaN%:\n",
      " sent_mean_poly        1.000000\n",
      "sent_count            0.954545\n",
      "sent_count_poly       0.954545\n",
      "sent_mean_fin         0.954545\n",
      "sent_mean_weighted    0.954545\n",
      "sent_mean             0.954545\n",
      "eps_surprise_mean     0.954545\n",
      "eps_surprise_last     0.954545\n",
      "sent_count_fin        0.954545\n",
      "inflation_yoy_lag6    0.136364\n",
      "Saved → data_enriched/META_features_enriched.csv\n",
      "Features for AMZN ...\n",
      "\n",
      "[Diag] AMZN features: shape=(88, 42), index=(2018-07-31 00:00:00, 2025-10-31 00:00:00)\n",
      "[Diag] Top columns by NaN%:\n",
      " sent_mean_poly        1.000000\n",
      "sent_count            0.954545\n",
      "sent_count_poly       0.954545\n",
      "sent_mean_fin         0.954545\n",
      "sent_mean_weighted    0.954545\n",
      "sent_mean             0.954545\n",
      "eps_surprise_mean     0.954545\n",
      "eps_surprise_last     0.954545\n",
      "sent_count_fin        0.954545\n",
      "inflation_yoy_lag6    0.136364\n",
      "Saved → data_enriched/AMZN_features_enriched.csv\n",
      "Saved → data_enriched/tech_features_combined.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\SyedM\\AppData\\Local\\Temp\\ipykernel_6708\\934960800.py:9: FutureWarning: 'M' is deprecated and will be removed in a future version, please use 'ME' instead.\n",
      "  m = close.resample(\"M\").last()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr:last-of-type th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"10\" halign=\"left\">AAPL</th>\n",
       "      <th>...</th>\n",
       "      <th colspan=\"10\" halign=\"left\">AMZN</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>AAPL_ret</th>\n",
       "      <th>ixic_ret</th>\n",
       "      <th>xlk_ret</th>\n",
       "      <th>ai_basket_ret</th>\n",
       "      <th>sent_mean</th>\n",
       "      <th>sent_count</th>\n",
       "      <th>sent_mean_weighted</th>\n",
       "      <th>sent_mean_poly</th>\n",
       "      <th>sent_count_poly</th>\n",
       "      <th>sent_mean_fin</th>\n",
       "      <th>...</th>\n",
       "      <th>fed_funds_rate_lag6</th>\n",
       "      <th>fedfunds_chg_lag1</th>\n",
       "      <th>fedfunds_chg_lag3</th>\n",
       "      <th>fedfunds_chg_lag6</th>\n",
       "      <th>unemployment_rate_lag1</th>\n",
       "      <th>unemployment_rate_lag3</th>\n",
       "      <th>unemployment_rate_lag6</th>\n",
       "      <th>unrate_chg_lag1</th>\n",
       "      <th>unrate_chg_lag3</th>\n",
       "      <th>unrate_chg_lag6</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2025-06-30</th>\n",
       "      <td>0.021509</td>\n",
       "      <td>0.065710</td>\n",
       "      <td>0.098479</td>\n",
       "      <td>0.140136</td>\n",
       "      <td>0.443481</td>\n",
       "      <td>112.0</td>\n",
       "      <td>0.443481</td>\n",
       "      <td>0.443481</td>\n",
       "      <td>112.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4.48</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.16</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-07-31</th>\n",
       "      <td>0.011698</td>\n",
       "      <td>0.036953</td>\n",
       "      <td>0.037555</td>\n",
       "      <td>0.107196</td>\n",
       "      <td>0.501022</td>\n",
       "      <td>196.0</td>\n",
       "      <td>0.501022</td>\n",
       "      <td>0.501022</td>\n",
       "      <td>196.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.15</td>\n",
       "      <td>4.1</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-08-31</th>\n",
       "      <td>0.119639</td>\n",
       "      <td>0.015770</td>\n",
       "      <td>-0.001104</td>\n",
       "      <td>-0.011649</td>\n",
       "      <td>0.503038</td>\n",
       "      <td>195.0</td>\n",
       "      <td>0.503038</td>\n",
       "      <td>0.503038</td>\n",
       "      <td>195.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.1</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-09-30</th>\n",
       "      <td>0.096881</td>\n",
       "      <td>0.056137</td>\n",
       "      <td>0.075337</td>\n",
       "      <td>0.056200</td>\n",
       "      <td>0.417668</td>\n",
       "      <td>324.0</td>\n",
       "      <td>0.417668</td>\n",
       "      <td>0.466827</td>\n",
       "      <td>194.0</td>\n",
       "      <td>0.344308</td>\n",
       "      <td>...</td>\n",
       "      <td>4.33</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>4.3</td>\n",
       "      <td>4.1</td>\n",
       "      <td>4.2</td>\n",
       "      <td>0.1</td>\n",
       "      <td>-0.1</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2025-10-31</th>\n",
       "      <td>0.013313</td>\n",
       "      <td>0.005318</td>\n",
       "      <td>0.010147</td>\n",
       "      <td>0.004113</td>\n",
       "      <td>0.416321</td>\n",
       "      <td>118.0</td>\n",
       "      <td>0.416321</td>\n",
       "      <td>0.229520</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.443525</td>\n",
       "      <td>...</td>\n",
       "      <td>4.33</td>\n",
       "      <td>-0.11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.2</td>\n",
       "      <td>4.2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.1</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 252 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                AAPL                                                         \\\n",
       "            AAPL_ret  ixic_ret   xlk_ret ai_basket_ret sent_mean sent_count   \n",
       "Date                                                                          \n",
       "2025-06-30  0.021509  0.065710  0.098479      0.140136  0.443481      112.0   \n",
       "2025-07-31  0.011698  0.036953  0.037555      0.107196  0.501022      196.0   \n",
       "2025-08-31  0.119639  0.015770 -0.001104     -0.011649  0.503038      195.0   \n",
       "2025-09-30  0.096881  0.056137  0.075337      0.056200  0.417668      324.0   \n",
       "2025-10-31  0.013313  0.005318  0.010147      0.004113  0.416321      118.0   \n",
       "\n",
       "                                                                            \\\n",
       "           sent_mean_weighted sent_mean_poly sent_count_poly sent_mean_fin   \n",
       "Date                                                                         \n",
       "2025-06-30           0.443481       0.443481           112.0           NaN   \n",
       "2025-07-31           0.501022       0.501022           196.0           NaN   \n",
       "2025-08-31           0.503038       0.503038           195.0           NaN   \n",
       "2025-09-30           0.417668       0.466827           194.0      0.344308   \n",
       "2025-10-31           0.416321       0.229520            15.0      0.443525   \n",
       "\n",
       "            ...                AMZN                                      \\\n",
       "            ... fed_funds_rate_lag6 fedfunds_chg_lag1 fedfunds_chg_lag3   \n",
       "Date        ...                                                           \n",
       "2025-06-30  ...                4.48              0.00               0.0   \n",
       "2025-07-31  ...                4.33              0.00               0.0   \n",
       "2025-08-31  ...                4.33              0.00               0.0   \n",
       "2025-09-30  ...                4.33              0.00               0.0   \n",
       "2025-10-31  ...                4.33             -0.11               0.0   \n",
       "\n",
       "                                                                            \\\n",
       "           fedfunds_chg_lag6 unemployment_rate_lag1 unemployment_rate_lag3   \n",
       "Date                                                                         \n",
       "2025-06-30             -0.16                    4.2                    4.2   \n",
       "2025-07-31             -0.15                    4.1                    4.2   \n",
       "2025-08-31              0.00                    4.2                    4.2   \n",
       "2025-09-30              0.00                    4.3                    4.1   \n",
       "2025-10-31              0.00                    NaN                    4.2   \n",
       "\n",
       "                                                                   \\\n",
       "           unemployment_rate_lag6 unrate_chg_lag1 unrate_chg_lag3   \n",
       "Date                                                                \n",
       "2025-06-30                    4.1             0.0             0.1   \n",
       "2025-07-31                    4.0            -0.1             0.0   \n",
       "2025-08-31                    4.1             0.1             0.0   \n",
       "2025-09-30                    4.2             0.1            -0.1   \n",
       "2025-10-31                    4.2             NaN             0.1   \n",
       "\n",
       "                            \n",
       "           unrate_chg_lag6  \n",
       "Date                        \n",
       "2025-06-30            -0.1  \n",
       "2025-07-31            -0.1  \n",
       "2025-08-31             0.1  \n",
       "2025-09-30             0.1  \n",
       "2025-10-31             0.0  \n",
       "\n",
       "[5 rows x 252 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def build_ticker_features(ticker: str) -> pd.DataFrame:\n",
    "    close, rets = monthly_from_yf(ticker, START, END)\n",
    "    t_ret = rets.rename(columns={rets.columns[0]: f\"{ticker}_ret\"})\n",
    "    feats = t_ret.join(ixic_rets, how=\"left\").join(xlk_rets, how=\"left\").join(ai_ret_eqw, how=\"left\")\n",
    "    if ticker in news_sent_maps: feats = feats.join(news_sent_maps[ticker], how=\"left\")\n",
    "    if ticker in earnings_maps: feats = feats.join(earnings_maps[ticker], how=\"left\")\n",
    "    base_feats = [\"inflation_yoy\",\"us10y\",\"us10y_chg\",\"fed_funds_rate\",\"fedfunds_chg\",\"unemployment_rate\",\"unrate_chg\"]\n",
    "    macro_lagged = make_lags(macro, base_feats, lags=LAGS)\n",
    "    feats = feats.join(macro_lagged, how=\"left\")\n",
    "    max_lag = max(LAGS) if LAGS else 0\n",
    "    if len(feats) > max_lag:\n",
    "        feats = feats.iloc[max_lag:]\n",
    "    return feats\n",
    "\n",
    "all_feat = {}\n",
    "for t in TECH_TICKERS:\n",
    "    print(f\"Features for {t} ...\")\n",
    "    ft = build_ticker_features(t)\n",
    "    diagnostics(ft, f\"{t} features\")\n",
    "    all_feat[t] = ft\n",
    "    _to_csv(ft, f\"{OUT_DIR}/{t}_features_enriched.csv\")\n",
    "\n",
    "combined = pd.concat(all_feat, axis=1)\n",
    "_to_csv(combined, f\"{OUT_DIR}/tech_features_combined.csv\")\n",
    "combined.tail()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5bf661",
   "metadata": {},
   "source": [
    "## Safe OLS per ticker\n",
    "\n",
    "Simple Ordinary Least Squares, which is one of the most common methods for estimating the parameters of a linear regression model. This will:\n",
    "\n",
    "* Selects best-covered features (limits to a max count) so you don’t lose the sample to sparsity.\n",
    "\n",
    "* Fits per-ticker OLS with a minimum-row guard; prints summary if enough data.\n",
    "\n",
    "* Reports row counts before/after dropna."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "574c9286",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== AAPL OLS (enriched) ===\n",
      "rows_before=88, rows_after_dropna=86, features=20\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:               AAPL_ret   R-squared:                       0.740\n",
      "Model:                            OLS   Adj. R-squared:                  0.665\n",
      "Method:                 Least Squares   F-statistic:                     9.878\n",
      "Date:                Sun, 05 Oct 2025   Prob (F-statistic):           8.91e-13\n",
      "Time:                        07:33:13   Log-Likelihood:                 148.25\n",
      "No. Observations:                  86   AIC:                            -256.5\n",
      "Df Residuals:                      66   BIC:                            -207.4\n",
      "Df Model:                          19                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==========================================================================================\n",
      "                             coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------\n",
      "const                      0.0215      0.046      0.466      0.643      -0.071       0.114\n",
      "ixic_ret                   0.0966      0.391      0.247      0.805      -0.683       0.876\n",
      "xlk_ret                    1.6143      0.382      4.221      0.000       0.851       2.378\n",
      "ai_basket_ret             -0.5911      0.159     -3.708      0.000      -0.909      -0.273\n",
      "us10y                     -0.0138      0.015     -0.908      0.367      -0.044       0.016\n",
      "fed_funds_rate_lag1       -0.0110      0.062     -0.177      0.860      -0.135       0.113\n",
      "fed_funds_rate_lag3        0.0160      0.080      0.200      0.842      -0.144       0.176\n",
      "us10y_lag1                 0.0028      0.021      0.137      0.892      -0.039       0.044\n",
      "fed_funds_rate_lag6       -0.0072      0.032     -0.227      0.821      -0.070       0.056\n",
      "us10y_lag3                -0.0118      0.035     -0.336      0.738      -0.082       0.058\n",
      "us10y_lag6                 0.0192      0.021      0.896      0.374      -0.024       0.062\n",
      "us10y_chg_lag1            -0.0074      0.050     -0.148      0.883      -0.108       0.093\n",
      "us10y_chg_lag3             0.0342      0.036      0.961      0.340      -0.037       0.105\n",
      "us10y_chg                 -0.0166      0.020     -0.833      0.408      -0.056       0.023\n",
      "unemployment_rate_lag6    -0.0042      0.005     -0.864      0.391      -0.014       0.006\n",
      "fedfunds_chg_lag3         -0.0144      0.064     -0.226      0.822      -0.142       0.113\n",
      "fedfunds_chg_lag1         -0.0212      0.086     -0.247      0.806      -0.192       0.150\n",
      "unemployment_rate_lag3     0.0063      0.008      0.781      0.438      -0.010       0.023\n",
      "unrate_chg_lag3            0.0043      0.006      0.660      0.511      -0.009       0.017\n",
      "fedfunds_chg_lag6          0.0634      0.040      1.595      0.116      -0.016       0.143\n",
      "unemployment_rate_lag1    -0.0012      0.006     -0.195      0.846      -0.013       0.011\n",
      "==============================================================================\n",
      "Omnibus:                        7.194   Durbin-Watson:                   1.718\n",
      "Prob(Omnibus):                  0.027   Jarque-Bera (JB):               13.202\n",
      "Skew:                          -0.087   Prob(JB):                      0.00136\n",
      "Kurtosis:                       4.912   Cond. No.                     4.52e+16\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 4.99e-30. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n",
      "\n",
      "=== MSFT OLS (enriched) ===\n",
      "rows_before=88, rows_after_dropna=86, features=20\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:               MSFT_ret   R-squared:                       0.803\n",
      "Model:                            OLS   Adj. R-squared:                  0.746\n",
      "Method:                 Least Squares   F-statistic:                     14.17\n",
      "Date:                Sun, 05 Oct 2025   Prob (F-statistic):           1.77e-16\n",
      "Time:                        07:33:13   Log-Likelihood:                 186.41\n",
      "No. Observations:                  86   AIC:                            -332.8\n",
      "Df Residuals:                      66   BIC:                            -283.7\n",
      "Df Model:                          19                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==========================================================================================\n",
      "                             coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------\n",
      "const                      0.0386      0.030      1.303      0.197      -0.021       0.098\n",
      "ixic_ret                  -0.2614      0.251     -1.043      0.301      -0.762       0.239\n",
      "xlk_ret                    0.8890      0.245      3.623      0.001       0.399       1.379\n",
      "ai_basket_ret              0.2201      0.102      2.152      0.035       0.016       0.424\n",
      "us10y                      0.0046      0.010      0.477      0.635      -0.015       0.024\n",
      "fed_funds_rate_lag1       -0.0312      0.040     -0.782      0.437      -0.111       0.048\n",
      "fed_funds_rate_lag3        0.0392      0.051      0.765      0.447      -0.063       0.142\n",
      "us10y_lag1                 0.0084      0.013      0.628      0.532      -0.018       0.035\n",
      "fed_funds_rate_lag6       -0.0077      0.020     -0.378      0.707      -0.048       0.033\n",
      "us10y_lag3                -0.0066      0.023     -0.295      0.769      -0.052       0.038\n",
      "us10y_lag6                -0.0118      0.014     -0.855      0.395      -0.039       0.016\n",
      "us10y_chg_lag1            -0.0246      0.032     -0.764      0.447      -0.089       0.040\n",
      "us10y_chg_lag3            -0.0429      0.023     -1.879      0.065      -0.089       0.003\n",
      "us10y_chg                 -0.0038      0.013     -0.295      0.769      -0.029       0.022\n",
      "unemployment_rate_lag6    -0.0009      0.003     -0.298      0.766      -0.007       0.005\n",
      "fedfunds_chg_lag3         -0.0544      0.041     -1.330      0.188      -0.136       0.027\n",
      "fedfunds_chg_lag1          0.0697      0.055      1.266      0.210      -0.040       0.180\n",
      "unemployment_rate_lag3 -4.524e-05      0.005     -0.009      0.993      -0.010       0.010\n",
      "unrate_chg_lag3           -0.0053      0.004     -1.286      0.203      -0.014       0.003\n",
      "fedfunds_chg_lag6          0.0024      0.026      0.096      0.924      -0.049       0.053\n",
      "unemployment_rate_lag1    -0.0039      0.004     -1.027      0.308      -0.011       0.004\n",
      "==============================================================================\n",
      "Omnibus:                        6.709   Durbin-Watson:                   2.183\n",
      "Prob(Omnibus):                  0.035   Jarque-Bera (JB):                6.112\n",
      "Skew:                           0.554   Prob(JB):                       0.0471\n",
      "Kurtosis:                       3.693   Cond. No.                     4.52e+16\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 4.99e-30. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n",
      "\n",
      "=== GOOGL OLS (enriched) ===\n",
      "rows_before=88, rows_after_dropna=86, features=20\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:              GOOGL_ret   R-squared:                       0.661\n",
      "Model:                            OLS   Adj. R-squared:                  0.563\n",
      "Method:                 Least Squares   F-statistic:                     6.772\n",
      "Date:                Sun, 05 Oct 2025   Prob (F-statistic):           2.22e-09\n",
      "Time:                        07:33:13   Log-Likelihood:                 146.57\n",
      "No. Observations:                  86   AIC:                            -253.1\n",
      "Df Residuals:                      66   BIC:                            -204.1\n",
      "Df Model:                          19                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==========================================================================================\n",
      "                             coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------\n",
      "const                     -0.0315      0.047     -0.670      0.505      -0.125       0.062\n",
      "ixic_ret                   0.9374      0.398      2.354      0.022       0.142       1.733\n",
      "xlk_ret                   -0.5105      0.390     -1.309      0.195      -1.289       0.268\n",
      "ai_basket_ret              0.4168      0.163      2.564      0.013       0.092       0.741\n",
      "us10y                      0.0375      0.015      2.426      0.018       0.007       0.068\n",
      "fed_funds_rate_lag1        0.0023      0.063      0.037      0.971      -0.124       0.129\n",
      "fed_funds_rate_lag3        0.0039      0.082      0.048      0.962      -0.159       0.167\n",
      "us10y_lag1                 0.0341      0.021      1.606      0.113      -0.008       0.077\n",
      "fed_funds_rate_lag6       -0.0091      0.032     -0.281      0.779      -0.073       0.055\n",
      "us10y_lag3                -0.1050      0.036     -2.932      0.005      -0.176      -0.033\n",
      "us10y_lag6                 0.0412      0.022      1.881      0.064      -0.003       0.085\n",
      "us10y_chg_lag1            -0.1123      0.051     -2.196      0.032      -0.214      -0.010\n",
      "us10y_chg_lag3             0.0155      0.036      0.428      0.670      -0.057       0.088\n",
      "us10y_chg                  0.0033      0.020      0.163      0.871      -0.037       0.044\n",
      "unemployment_rate_lag6     0.0080      0.005      1.606      0.113      -0.002       0.018\n",
      "fedfunds_chg_lag3          0.0239      0.065      0.367      0.715      -0.106       0.154\n",
      "fedfunds_chg_lag1         -0.0374      0.087     -0.427      0.671      -0.212       0.137\n",
      "unemployment_rate_lag3    -0.0043      0.008     -0.513      0.610      -0.021       0.012\n",
      "unrate_chg_lag3            0.0014      0.007      0.209      0.835      -0.012       0.015\n",
      "fedfunds_chg_lag6         -0.0278      0.041     -0.684      0.496      -0.109       0.053\n",
      "unemployment_rate_lag1     0.0006      0.006      0.106      0.916      -0.011       0.013\n",
      "==============================================================================\n",
      "Omnibus:                        3.050   Durbin-Watson:                   2.049\n",
      "Prob(Omnibus):                  0.218   Jarque-Bera (JB):                2.772\n",
      "Skew:                           0.439   Prob(JB):                        0.250\n",
      "Kurtosis:                       2.969   Cond. No.                     4.52e+16\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 4.99e-30. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n",
      "\n",
      "=== NVDA OLS (enriched) ===\n",
      "rows_before=88, rows_after_dropna=86, features=20\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:               NVDA_ret   R-squared:                       0.812\n",
      "Model:                            OLS   Adj. R-squared:                  0.758\n",
      "Method:                 Least Squares   F-statistic:                     14.99\n",
      "Date:                Sun, 05 Oct 2025   Prob (F-statistic):           4.32e-17\n",
      "Time:                        07:33:13   Log-Likelihood:                 117.62\n",
      "No. Observations:                  86   AIC:                            -195.2\n",
      "Df Residuals:                      66   BIC:                            -146.1\n",
      "Df Model:                          19                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==========================================================================================\n",
      "                             coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------\n",
      "const                      0.0851      0.066      1.292      0.201      -0.046       0.217\n",
      "ixic_ret                  -0.9124      0.558     -1.636      0.107      -2.026       0.201\n",
      "xlk_ret                    0.6265      0.546      1.147      0.255      -0.464       1.717\n",
      "ai_basket_ret              1.5869      0.228      6.971      0.000       1.132       2.041\n",
      "us10y                     -0.0456      0.022     -2.108      0.039      -0.089      -0.002\n",
      "fed_funds_rate_lag1        0.1756      0.089      1.976      0.052      -0.002       0.353\n",
      "fed_funds_rate_lag3       -0.2142      0.114     -1.876      0.065      -0.442       0.014\n",
      "us10y_lag1                -0.1038      0.030     -3.486      0.001      -0.163      -0.044\n",
      "fed_funds_rate_lag6        0.0742      0.045      1.645      0.105      -0.016       0.164\n",
      "us10y_lag3                 0.1285      0.050      2.563      0.013       0.028       0.229\n",
      "us10y_lag6                -0.0360      0.031     -1.173      0.245      -0.097       0.025\n",
      "us10y_chg_lag1             0.2254      0.072      3.146      0.002       0.082       0.368\n",
      "us10y_chg_lag3             0.0127      0.051      0.249      0.804      -0.089       0.114\n",
      "us10y_chg                  0.0582      0.028      2.044      0.045       0.001       0.115\n",
      "unemployment_rate_lag6    -0.0030      0.007     -0.430      0.669      -0.017       0.011\n",
      "fedfunds_chg_lag3          0.0879      0.091      0.965      0.338      -0.094       0.270\n",
      "fedfunds_chg_lag1         -0.1439      0.123     -1.175      0.244      -0.389       0.101\n",
      "unemployment_rate_lag3    -0.0142      0.012     -1.225      0.225      -0.037       0.009\n",
      "unrate_chg_lag3           -0.0043      0.009     -0.470      0.640      -0.023       0.014\n",
      "fedfunds_chg_lag6         -0.0096      0.057     -0.168      0.867      -0.123       0.104\n",
      "unemployment_rate_lag1     0.0131      0.008      1.559      0.124      -0.004       0.030\n",
      "==============================================================================\n",
      "Omnibus:                        0.212   Durbin-Watson:                   1.849\n",
      "Prob(Omnibus):                  0.900   Jarque-Bera (JB):                0.399\n",
      "Skew:                          -0.027   Prob(JB):                        0.819\n",
      "Kurtosis:                       2.670   Cond. No.                     4.52e+16\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 4.99e-30. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n",
      "\n",
      "=== META OLS (enriched) ===\n",
      "rows_before=88, rows_after_dropna=86, features=20\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:               META_ret   R-squared:                       0.661\n",
      "Model:                            OLS   Adj. R-squared:                  0.564\n",
      "Method:                 Least Squares   F-statistic:                     6.786\n",
      "Date:                Sun, 05 Oct 2025   Prob (F-statistic):           2.14e-09\n",
      "Time:                        07:33:13   Log-Likelihood:                 112.76\n",
      "No. Observations:                  86   AIC:                            -185.5\n",
      "Df Residuals:                      66   BIC:                            -136.4\n",
      "Df Model:                          19                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==========================================================================================\n",
      "                             coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------\n",
      "const                     -0.0496      0.070     -0.711      0.479      -0.189       0.090\n",
      "ixic_ret                   0.8289      0.590      1.405      0.165      -0.349       2.007\n",
      "xlk_ret                   -0.9221      0.578     -1.596      0.115      -2.076       0.232\n",
      "ai_basket_ret              0.9398      0.241      3.901      0.000       0.459       1.421\n",
      "us10y                      0.0201      0.023      0.877      0.384      -0.026       0.066\n",
      "fed_funds_rate_lag1       -0.1168      0.094     -1.243      0.218      -0.305       0.071\n",
      "fed_funds_rate_lag3        0.1638      0.121      1.356      0.180      -0.077       0.405\n",
      "us10y_lag1                 0.0347      0.032      1.101      0.275      -0.028       0.098\n",
      "fed_funds_rate_lag6       -0.0392      0.048     -0.821      0.414      -0.135       0.056\n",
      "us10y_lag3                -0.0233      0.053     -0.440      0.661      -0.129       0.083\n",
      "us10y_lag6                -0.0354      0.032     -1.091      0.279      -0.100       0.029\n",
      "us10y_chg_lag1            -0.1442      0.076     -1.903      0.061      -0.296       0.007\n",
      "us10y_chg_lag3            -0.0071      0.054     -0.132      0.895      -0.114       0.100\n",
      "us10y_chg                 -0.0146      0.030     -0.486      0.629      -0.075       0.046\n",
      "unemployment_rate_lag6    -0.0060      0.007     -0.811      0.420      -0.021       0.009\n",
      "fedfunds_chg_lag3          0.0025      0.096      0.026      0.979      -0.190       0.195\n",
      "fedfunds_chg_lag1          0.0800      0.130      0.617      0.539      -0.179       0.339\n",
      "unemployment_rate_lag3     0.0149      0.012      1.210      0.231      -0.010       0.039\n",
      "unrate_chg_lag3           -0.0023      0.010     -0.239      0.812      -0.022       0.017\n",
      "fedfunds_chg_lag6          0.1093      0.060      1.819      0.074      -0.011       0.229\n",
      "unemployment_rate_lag1    -0.0011      0.009     -0.127      0.899      -0.019       0.017\n",
      "==============================================================================\n",
      "Omnibus:                       13.317   Durbin-Watson:                   2.229\n",
      "Prob(Omnibus):                  0.001   Jarque-Bera (JB):               18.007\n",
      "Skew:                          -0.700   Prob(JB):                     0.000123\n",
      "Kurtosis:                       4.751   Cond. No.                     4.52e+16\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 4.99e-30. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n",
      "\n",
      "=== AMZN OLS (enriched) ===\n",
      "rows_before=88, rows_after_dropna=86, features=20\n",
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:               AMZN_ret   R-squared:                       0.774\n",
      "Model:                            OLS   Adj. R-squared:                  0.710\n",
      "Method:                 Least Squares   F-statistic:                     11.93\n",
      "Date:                Sun, 05 Oct 2025   Prob (F-statistic):           1.16e-14\n",
      "Time:                        07:33:13   Log-Likelihood:                 148.03\n",
      "No. Observations:                  86   AIC:                            -256.1\n",
      "Df Residuals:                      66   BIC:                            -207.0\n",
      "Df Model:                          19                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==========================================================================================\n",
      "                             coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------------------\n",
      "const                      0.1170      0.046      2.530      0.014       0.025       0.209\n",
      "ixic_ret                   1.8882      0.392      4.822      0.000       1.106       2.670\n",
      "xlk_ret                   -1.1571      0.383     -3.018      0.004      -1.923      -0.392\n",
      "ai_basket_ret              0.4735      0.160      2.962      0.004       0.154       0.793\n",
      "us10y                     -0.0073      0.015     -0.481      0.632      -0.038       0.023\n",
      "fed_funds_rate_lag1        0.1394      0.062      2.234      0.029       0.015       0.264\n",
      "fed_funds_rate_lag3       -0.1587      0.080     -1.980      0.052      -0.319       0.001\n",
      "us10y_lag1                -0.0212      0.021     -1.012      0.315      -0.063       0.021\n",
      "fed_funds_rate_lag6        0.0311      0.032      0.980      0.330      -0.032       0.094\n",
      "us10y_lag3                 0.0034      0.035      0.095      0.924      -0.067       0.074\n",
      "us10y_lag6                -0.0049      0.022     -0.228      0.820      -0.048       0.038\n",
      "us10y_chg_lag1             0.0283      0.050      0.563      0.575      -0.072       0.129\n",
      "us10y_chg_lag3             0.0380      0.036      1.064      0.291      -0.033       0.109\n",
      "us10y_chg                  0.0139      0.020      0.693      0.491      -0.026       0.054\n",
      "unemployment_rate_lag6    -0.0045      0.005     -0.914      0.364      -0.014       0.005\n",
      "fedfunds_chg_lag3         -0.0900      0.064     -1.408      0.164      -0.218       0.038\n",
      "fedfunds_chg_lag1         -0.1411      0.086     -1.641      0.106      -0.313       0.031\n",
      "unemployment_rate_lag3    -0.0111      0.008     -1.361      0.178      -0.027       0.005\n",
      "unrate_chg_lag3            0.0021      0.006      0.327      0.745      -0.011       0.015\n",
      "fedfunds_chg_lag6          0.0152      0.040      0.381      0.705      -0.064       0.095\n",
      "unemployment_rate_lag1     0.0007      0.006      0.113      0.911      -0.011       0.012\n",
      "==============================================================================\n",
      "Omnibus:                        1.464   Durbin-Watson:                   2.152\n",
      "Prob(Omnibus):                  0.481   Jarque-Bera (JB):                1.519\n",
      "Skew:                           0.276   Prob(JB):                        0.468\n",
      "Kurtosis:                       2.655   Cond. No.                     4.52e+16\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 4.99e-30. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "def fit_ols_safe(df: pd.DataFrame, target_col: str, min_rows: int = 12):\n",
    "    X = df.drop(columns=[target_col])\n",
    "    y = df[target_col]\n",
    "    aligned = pd.concat([y, X], axis=1).dropna()\n",
    "    info = {\"rows_before\": len(df), \"rows_after_dropna\": len(aligned), \"n_features\": X.shape[1]}\n",
    "    if len(aligned) < min_rows:\n",
    "        return None, info\n",
    "    y_clean = aligned.iloc[:,0]\n",
    "    X_clean = aligned.iloc[:,1:]\n",
    "    X_clean = sm.add_constant(X_clean, has_constant=\"add\")\n",
    "    m = sm.OLS(y_clean, X_clean).fit()\n",
    "    return m, info\n",
    "\n",
    "def top_features_by_coverage(df: pd.DataFrame, target_col: str, k: int = 20):\n",
    "    na_rates = df.drop(columns=[target_col]).isna().mean()\n",
    "    keep_feats = na_rates.sort_values().index[:k].tolist()\n",
    "    cols = [target_col] + keep_feats\n",
    "    return df[cols]\n",
    "\n",
    "MIN_ROWS = 12\n",
    "MAX_FEATS = 20\n",
    "\n",
    "for t in TECH_TICKERS:\n",
    "    print(f\"\\n=== {t} OLS (enriched) ===\")\n",
    "    df_t = all_feat[t].copy()\n",
    "    target = f\"{t}_ret\"\n",
    "    df_t_red = top_features_by_coverage(df_t, target, k=MAX_FEATS)\n",
    "    m, info = fit_ols_safe(df_t_red, target, min_rows=MIN_ROWS)\n",
    "    print(f\"rows_before={info['rows_before']}, rows_after_dropna={info['rows_after_dropna']}, features={info['n_features']}\")\n",
    "    if m is None:\n",
    "        print(f\"Not enough data after dropna (need >= {MIN_ROWS}). Try longer date range, fewer lags, or fewer sparse features.\")\n",
    "        continue\n",
    "    try:\n",
    "        print(m.summary())\n",
    "    except Exception as e:\n",
    "        print(\"Could not print full summary:\", e)\n",
    "        print(\"Params:\\n\", m.params)\n",
    "        print(\"R2:\", getattr(m, \"rsquared\", None), \"Adj R2:\", getattr(m, \"rsquared_adj\", None))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05474424",
   "metadata": {},
   "source": [
    "# Outputs\n",
    "\n",
    "data_enriched/macro_monthly.csv\n",
    "\n",
    "data_enriched/ixic_rets.csv, xlk_rets.csv, ai_basket_rets.csv\n",
    "\n",
    "Per ticker:\n",
    "\n",
    "[TECH TICKER]_news_sentiment_combined.csv, …\n",
    "\n",
    "[TECH TICKER]_earnings_features.csv, …\n",
    "\n",
    "[TECH TICKER]_features_enriched.csv, …\n",
    "\n",
    "Panel: data_enriched/tech_features_combined.csv"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
